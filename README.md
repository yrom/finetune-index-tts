# IndexTTS Fine-tuning Demo

[ä¸­æ–‡è¯´æ˜Ž](README_zh.md)

This project is a demonstration of fine-tuning [IndexTTS](https://github.com/index-tts/index-tts) to generate speech with addtional special tags (such as `<GIGGLES>`), enabling the synthesis of non-textual elements like laughter.

## Goals

- Show you how to fine-tune IndexTTS's text Tokenizer (BPE) and AR part (GPT2).
- Support for addtional special tags like `<GIGGLES>` in text to generate laughter.

### Fine-tuning Dataset

[ðŸ¤— MrDragonFox/Elise](https://huggingface.co/datasets/MrDragonFox/Elise) ([Modelscope mirror](https://www.modelscope.cn/datasets/RealmSky/Elise))


### Fine-tuning Experiment Results Example

| Reference Audio | Text | Synthesized Speech |
| --- | --- | --- |
| [Female-1][Female_1]| Seriously? &lt;giggles> That's the cutest thing I've ever heard! | [Synthesized Speech](samples/Female-1_SeriouslygigglesThatsthecutestt.wav) |
| [Female-1][Female_1] | çœŸçš„å—ï¼Ÿ &lt;giggles> è¿™ä¹Ÿå¤ªå¯çˆ±äº†å§ï¼| [Synthesized Speech](samples/Female-1_çœŸçš„å—gigglesè¿™ä¹Ÿå¤ªå¯çˆ±äº†å§.wav) |
| [Male-1][Male_1]| Whaâ€”? Cute? &lt;giggles> You think I'm cute?! Well, uh, thanks, I guess? | [Synthesized Speech](samples/Male-1_Whaâ€”CutegigglesYouthinkImcute.wav) |
| [Male-1][Male_1]| å“Žå‘€! å¿˜äº†ä»–è¿˜åœ¨é‚£ç­‰æˆ‘ä»¬å‘¢ï¼&lt;giggles> æˆ‘ä»¬ä¸¤ä¸ªåŠ¨ä½œå¾—å¿«ç‚¹äº†ï¼| [Synthesized Speech](samples/Male-1_å“Žå‘€å¿˜äº†ä»–è¿˜åœ¨é‚£ç­‰æˆ‘ä»¬å‘¢gigglesæˆ‘ä»¬ä¸¤ä¸ªåŠ¨ä½œå¾—å¿«ç‚¹äº†.wav) |


### IndexTTS Architecture Overview

```mermaid
flowchart TD
    D("Reference Transcript") -->BPE[[**BPE**]] --> T(Text Token IDs)
    A("Reference Audio") --> M(Mel-Spectrogram) --> VAE[[*DiscreteVAE*]]--> B(Mel-Spec Code Ids)
    A -->CE[[*Conformer Encoder*]] --> Pe[[*Perceiver Resampler*]] --> CA(Audio Context Vector) -->|Conditioning| C
    B --> C
    T --> C[[**GPT2**]]
    C --> L("Latent Speech Representation")
    L --> V[["*BigVGAN*
    (Generator)"]]
    A --> SP[[*ECAPA-TDNN*]]--> S(Speaker Embedding)
    S --> V
    V -->|Synthesis| PCM("Waveform (PCM)") --> W("Synthesized Speech")
```

### Modules Fine-tuned in This Project

- **BPE**: Actually `sentencepiece`, this project show you how to adding new special tags such as `<GIGGLES>` to the text Tokenizer. See the [preprocess_mel_dataset.ipynb](preprocess_mel_dataset.ipynb) notebook for details.
- **GPT2**: The autoregressive model part, using the [ðŸ¤— peft](https://huggingface.co/docs/peft/v0.15.0/en/index) library for `LoRA` fine-tuning, supporting the generation of speech latents for text with special tags. See the [fine_tune_indextts.ipynb](fine_tune_indextts.ipynb) notebook for details.

## Disclaimer

The reference audio files and the datasets used in this project are granted under the [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.
They are used for the research and demonstration purposes of this project only, and are not intended for any commercial use.
The synthesized audio files generated by this project are also not intended for commercial use.

[Female_1]: https://bytedancespeech.github.io/seedtts_tech_report/audios/SpeechFactorization_samples/prompt/prompt1/4813840990459345930.wav
[Male_1]: https://bytedancespeech.github.io/seedtts_tech_report/audios/SpeechFactorization_samples/source/2188769758301752050.wav


## License

This project is licensed under the [MIT License](LICENSE).